{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Regression with `statsmodels`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multiple linear regression is simply a linear regression that involves more than one predictor variable. It is represented as:\n",
    "$$\\qquad Y_e = \\alpha + \\beta_1*X_1  + \\beta_2*X_2 + \\dots  + \\beta_p*X_p$$  \n",
    "\n",
    "Each *β<sub>i</sub>* will be estimated using the least sum of squares method.\n",
    "\n",
    "The data set is  \n",
    "$$ \\begin{array} \n",
    "       {~~}  Y_1, &  X_1^{(1)},  &  \\ldots, &  X_p^{(1)} \\\\\n",
    "        Y_2, &  X_1^{(2)},  &  \\ldots, &  X_p^{(2)} \\\\\n",
    "       \\vdots  & \\vdots  & \\vdots & \\vdots \\\\\n",
    "      Y_n, &  X_1^{(n)},  &  \\ldots, &  X_p^{(n)} \n",
    "    \\end{array}\n",
    "$$\n",
    "For each sample $i$, the predicted value by the model is:  $\\qquad Y_{i,e} = \\alpha + \\beta_1*X_1^{(i)}  + \\beta_2*X_2^{(i)} + \\dots  + \\beta_p*X_p^{(i)}$  \n",
    "\n",
    "\n",
    "Define the sum of squares \n",
    "$$   S(\\alpha,\\beta_1,\\ldots,\\beta_p) = \\sum_{i=1}^n \n",
    "\\left\\{     Y_i -Y_{i,e}\\right\\}^2  =\\sum_{i=1}^n \\left\\{ \n",
    "    Y_i -\\left( \\alpha + \\beta_1*X_1^{(i)}  + \\beta_2*X_2^{(i)} + \\dots  + \\beta_p*X_p^{(i)}\\right)\\right\\}^2\n",
    "$$\n",
    "Least squares estimators: solve \n",
    "$$ \\frac{\\partial  S(\\alpha,\\beta_1,\\ldots,\\beta_p)}{\\partial \\alpha}=0,\\quad \n",
    "\\frac{\\partial S (\\alpha,\\beta_1,\\ldots,\\beta_p)}{\\partial \\beta_1}=0,\\quad \\ldots,\\quad\n",
    "\\frac{\\partial S (\\alpha,\\beta_1,\\ldots,\\beta_p)}{\\partial \\beta_p}=0. \n",
    "$$\n",
    "to obtain the `least squares estimators` of the parameters\n",
    "$$ \\hat\\alpha, \\hat\\beta_1,\\ldots,\\hat\\beta_p.\n",
    "$$\n",
    "Note that be definition, \n",
    "$$      SSD = S(\\hat\\alpha, \\hat\\beta_1,\\ldots,\\hat\\beta_p).\n",
    "$$\n",
    "In other words, the fitted SSD (difference of sum of squares) is the minimized value of the sum squares with the estimated values of the parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`The more varibles, the smaller the $R^2$`\n",
    "\n",
    "Consider two regression models\n",
    "\n",
    "(I)   $\\quad ~ Y_e = \\alpha + \\beta_1*X_1$ \n",
    "\n",
    "(II)  $\\quad  \\tilde Y_e = \\alpha + \\beta_1*X_1  + \\beta_2*X_2 $\n",
    "\n",
    "The model (II) has one more input variable $X_2$. \n",
    "\n",
    "The $SSD_I$ of Model (I) is the minimum of\n",
    "\n",
    "$$   S_I(\\alpha,\\beta_1) = \\sum_{i=1}^n \\left\\{ \n",
    "    Y_i -\\left( \\alpha + \\beta_1*X_1^{(i)} \\right)\\right\\}^2\n",
    "$$\n",
    "over all possible values of $(\\alpha,\\beta_1)$.\n",
    "\n",
    "The $SSD_{II}$ of Model (II) is the minimum of \n",
    "\n",
    "$$   S_{II}(\\alpha,\\beta_1,\\beta_2) = \\sum_{i=1}^n \\left\\{ \n",
    "    Y_i -\\left( \\alpha + \\beta_1*X_1^{(i)} +\\beta_2*X_2^{(i)}  \\right)\\right\\}^2. \n",
    "$$\n",
    "over all possible values of $(\\alpha,\\beta_1,\\beta_2)$.\n",
    "\n",
    "Because  $\\quad S_I(\\alpha,\\beta_1) = S_{II}(\\alpha,\\beta_1,\\beta_2=0 )$, \n",
    "\n",
    "we find that $SSD_{II}\\le SSD_I$, so \n",
    "$$   R^2_{II} = SST - SSD_{II} \\ge SST - SSD_{I} =  R^2_{I}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this simple dataset of three predictor variables, there can be seven possible models:\n",
    "\n",
    "1. Sales ~ TV\n",
    "2. Sales ~ Newspaper\n",
    "3. Sales ~ Radio\n",
    "4. Sales ~ TV + Radio\n",
    "5. Sales ~ TV + Newspaper\n",
    "6. Sales ~ Newspaper + Radio\n",
    "7. Sales ~ TV + Radio + Newspaper\n",
    "\n",
    "Generally, if there are p possible predictor variables, there can be *(2<sup>p</sup> - 1)* possible models – this can get large very quickly!\n",
    "\n",
    "Thankfully, there are a few guidelines to filter some of these and then navigate towards the most efficient one.\n",
    "\n",
    "- Keep variables with low p-values and eliminate ones with high p-values\n",
    "- Keep variables that increase the value of **adjusted-*R<sup>2</sup>*** – this penalizes the model for adding insignificant variables and increases when we add significant variables. It is calculated by: \n",
    "$$ R^2_{adj} = 1- (1-R^2) \\frac{n-1}{n-p-1}$$\n",
    "\n",
    "Based on these guidelines, there are two approaches to select the predictor variables in the final model:\n",
    "\n",
    "- **Forward selection**: start with a null model (no predictors), then add predictors one by one. If the p-value for the variable is small enough and the value of the adjusted-*R<sup>2</sup>* goes up, the predictor is included in the model. Otherwise, it is not included.\n",
    "- **Backward selection**: starts with a model that has all the possible predictors and discard some of them. If the p-value of a predictor variable is large and adjusted-*R<sup>2</sup>* is lower when removed, it is discarded from the model. Otherwise, it remains a part of the model.\n",
    "\n",
    "Many statistical programs give us an option to select from these approaches while implementing multiple linear regression.\n",
    "\n",
    "For now, let’s manually add a few variables and see how it changes the model parameters and efficacy. First, add the `newspaper` variable to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Import and display first five rows of advertising dataset\n",
    "\n",
    "github_path = 'https://raw.githubusercontent.com/huangyh09/foundation-data-science/'\n",
    "dat_dir = github_path + 'main/w9-regression/'\n",
    "# dat_dir = './'\n",
    "\n",
    "advert = pd.read_csv('advertising.csv')\n",
    "advert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   R-squared:                       0.646\n",
      "Model:                            OLS   Adj. R-squared:                  0.642\n",
      "Method:                 Least Squares   F-statistic:                     179.6\n",
      "Date:                Mon, 01 Nov 2021   Prob (F-statistic):           3.95e-45\n",
      "Time:                        13:41:13   Log-Likelihood:                -509.89\n",
      "No. Observations:                 200   AIC:                             1026.\n",
      "Df Residuals:                     197   BIC:                             1036.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      5.7749      0.525     10.993      0.000       4.739       6.811\n",
      "TV             0.0469      0.003     18.173      0.000       0.042       0.052\n",
      "Newspaper      0.0442      0.010      4.346      0.000       0.024       0.064\n",
      "==============================================================================\n",
      "Omnibus:                        0.658   Durbin-Watson:                   1.969\n",
      "Prob(Omnibus):                  0.720   Jarque-Bera (JB):                0.415\n",
      "Skew:                          -0.093   Prob(JB):                        0.813\n",
      "Kurtosis:                       3.122   Cond. No.                         410.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Initialise and fit new model with TV and Newspaper as predictors\n",
    "model2 = smf.ols('Sales ~ TV + Newspaper', data=advert).fit()\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, the p-values for the coefficients are very small, suggesting that all the estimates are significant. The equation for this model will be:\n",
    "\n",
    " $$ \\text{Sales} = 5.77+0.046* \\text{TV} + 0.044 * \\text{Newspaper}$$\n",
    "\n",
    "The values of *R<sup>2</sup>* and adjusted *R<sup>2</sup>* are 0.646 and 0.642, which is just a minor improvement from before  (0.0612 and 0.0610, respectively).\n",
    "\n",
    "To calculate the RSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSE = 3.1207198602528856\n",
      "Mean sale = 14.022500000000003\n",
      "Error = 22.259999999999998%\n"
     ]
    }
   ],
   "source": [
    "# Store parameters\n",
    "alpha = model2.params[0]\n",
    "beta1 = model2.params[1]\n",
    "beta2 = model2.params[2]\n",
    "\n",
    "# Calculate RSE\n",
    "advert['sales_pred'] = model2.predict()\n",
    "advert['SSD'] = (advert['Sales'] - advert['sales_pred'])**2\n",
    "SSD = advert['SSD'].sum()\n",
    "RSE = np.sqrt(SSD / 197)   # n = 200, p = 2\n",
    "salesmean = np.mean(advert['Sales'])\n",
    "error = RSE / salesmean\n",
    "\n",
    "print(f'RSE = {RSE}\\nMean sale = {salesmean}\\nError = {np.round(error, 4)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only a small decrease in RSE and error...\n",
    "\n",
    "Let’s take a closer look at the summary above. The Adj-R<sup>2</sup> increases slightly, but the F-statistic decreases (from 312.1 to 179.6), as does the associated p-value. This suggests that adding `newspaper` didn't improve the model significantly.\n",
    "\n",
    "Let's try adding `radio` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   R-squared:                       0.897\n",
      "Model:                            OLS   Adj. R-squared:                  0.896\n",
      "Method:                 Least Squares   F-statistic:                     859.6\n",
      "Date:                Mon, 01 Nov 2021   Prob (F-statistic):           4.83e-98\n",
      "Time:                        13:41:13   Log-Likelihood:                -386.20\n",
      "No. Observations:                 200   AIC:                             778.4\n",
      "Df Residuals:                     197   BIC:                             788.3\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.9211      0.294      9.919      0.000       2.340       3.502\n",
      "TV             0.0458      0.001     32.909      0.000       0.043       0.048\n",
      "Radio          0.1880      0.008     23.382      0.000       0.172       0.204\n",
      "==============================================================================\n",
      "Omnibus:                       60.022   Durbin-Watson:                   2.081\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              148.679\n",
      "Skew:                          -1.323   Prob(JB):                     5.19e-33\n",
      "Kurtosis:                       6.292   Cond. No.                         425.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Initialise and fit new model with TV and Radio as predictors\n",
    "model3 = smf.ols('Sales ~ TV + Radio', data=advert).fit()\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the model:\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Ctext%7BSales%7D%3D2.92+0.046*%5Ctext%7BTV%7D+0.188*%5Ctext%7BRadio%7D)\n",
    "\n",
    "The adjusted *R<sup>2</sup>* value has improved considerably, as did the F-statistic, indicating an efficient model.\n",
    "\n",
    "The RSE can be calculated using the same method above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSE = 1.681360912508001\n",
      "Mean sale = 14.022500000000003\n",
      "Error = 11.99%\n"
     ]
    }
   ],
   "source": [
    "# Store parameters\n",
    "alpha = model3.params[0]\n",
    "beta1 = model3.params[1]\n",
    "beta2 = model3.params[2]\n",
    "\n",
    "# Calculate RSE\n",
    "advert['sales_pred'] = model3.predict()\n",
    "advert['SSD'] = (advert['Sales'] - advert['sales_pred'])**2\n",
    "SSD = advert['SSD'].sum()\n",
    "RSE = np.sqrt(SSD / 197)   # n = 200, p = 2\n",
    "salesmean = np.mean(advert['Sales'])\n",
    "error = RSE / salesmean\n",
    "\n",
    "print(f'RSE = {RSE}\\nMean sale = {salesmean}\\nError = {np.round(error, 4)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An improvement!\n",
    "\n",
    "Thus, we can conclude that `radio` is a great addition to the model.  `TV` and `radio` advertising costs together are able to predict sales well. But, can we improve it a bit further by combining all three predictor variables?\n",
    "\n",
    "See if you can figure out how to do this on your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise and fit new model with TV, Newspaper, and Radio as predictors\n",
    "\n",
    "# Print summary of regression results\n",
    "\n",
    "# Store parameters - there are now three betas\n",
    "\n",
    "# Calculate RSE - don't forget that the number of predictors p is now 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the equation:\n",
    "\n",
    "$$ \\text{Sales} = 2.939+0.046*\\text{TV} -0.001*\\text{Newspaper} +0.188*\\text{Radio}$$\n",
    "\n",
    "\n",
    "You should also find that:\n",
    "\n",
    "- RSE increases slightly,\n",
    "- the coefficient for `newspaper` is negative, and\n",
    "- the F-statistic decreases considerably from 859.6 to 570.3.\n",
    "\n",
    "All these suggest that the model actually became less efficient on addition of `newspaper`. \n",
    "\n",
    "Why?\n",
    "\n",
    "This step shows clearly that adding one more input variable `Newspaper` in Model 3 does not lead to any improvement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we manually checked a few combanations of input variables to reach an acceptable choice. There are more systematic approaches to select the predictor variables in a final model:\n",
    "\n",
    "- **Forward selection**: start with a null model (no predictors), then add predictors one by one. If the p-value for the variable is small enough and the value of the adjusted-*R<sup>2</sup>* goes up, the predictor is included in the model. Otherwise, it is not included.\n",
    "- **Backward selection**: starts with a model that has all the possible predictors and discard some of them. If the p-value of a predictor variable is large and adjusted-*R<sup>2</sup>* is lower when removed, it is discarded from the model. Otherwise, it remains a part of the model.\n",
    "\n",
    "Many statistical programs give us an option to select from these approaches while implementing multiple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
